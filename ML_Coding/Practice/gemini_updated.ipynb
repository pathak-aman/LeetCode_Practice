{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nToy Example: Basic End-to-End ML Workflow (Classification)\\n\\nDemonstrates the key steps for a timed ML technical interview scenario:\\n1. Load & Inspect Data\\n1b. Univariate Visualization (NEW)\\n2. Basic EDA & Preprocessing Strategy\\n3. Train/Test Split\\n4. Preprocessing (Imputation, Encoding, Scaling) using Pipelines\\n5. Train Baseline Model with Cross-Validation (UPDATED)\\n6. Evaluate Model on Test Set\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Toy Example: Basic End-to-End ML Workflow (Classification)\n",
    "\n",
    "Demonstrates the key steps for a timed ML technical interview scenario:\n",
    "1. Load & Inspect Data\n",
    "1b. Univariate Visualization (NEW)\n",
    "2. Basic EDA & Preprocessing Strategy\n",
    "3. Train/Test Split\n",
    "4. Preprocessing (Imputation, Encoding, Scaling) using Pipelines\n",
    "5. Train Baseline Model with Cross-Validation (UPDATED)\n",
    "6. Evaluate Model on Test Set\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "# Set plot style\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Create & Load Toy Dataset ---\n",
    "df = pd.read_csv(\"../data/kaggle_toy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initial Data ---\n",
      "   id     Podcast_Name Episode_Title  Episode_Length_minutes       Genre  \\\n",
      "0   0  Mystery Matters    Episode 98                     NaN  True Crime   \n",
      "1   1    Joke Junction    Episode 26                  119.80      Comedy   \n",
      "2   2   Study Sessions    Episode 16                   73.90   Education   \n",
      "3   3   Digital Digest    Episode 45                   67.17  Technology   \n",
      "4   4      Mind & Body    Episode 86                  110.51      Health   \n",
      "\n",
      "   Host_Popularity_percentage Publication_Day Publication_Time  \\\n",
      "0                       74.81        Thursday            Night   \n",
      "1                       66.95        Saturday        Afternoon   \n",
      "2                       69.97         Tuesday          Evening   \n",
      "3                       57.22          Monday          Morning   \n",
      "4                       80.07          Monday        Afternoon   \n",
      "\n",
      "   Guest_Popularity_percentage  Number_of_Ads Episode_Sentiment  \\\n",
      "0                          NaN            0.0          Positive   \n",
      "1                        75.95            2.0          Negative   \n",
      "2                         8.97            0.0          Negative   \n",
      "3                        78.70            2.0          Positive   \n",
      "4                        58.68            3.0           Neutral   \n",
      "\n",
      "   Listening_Time_minutes  \n",
      "0                31.41998  \n",
      "1                88.01241  \n",
      "2                44.92531  \n",
      "3                46.27824  \n",
      "4                75.61031  \n",
      "\n",
      "--- Data Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 12 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   id                           10000 non-null  int64  \n",
      " 1   Podcast_Name                 10000 non-null  object \n",
      " 2   Episode_Title                10000 non-null  object \n",
      " 3   Episode_Length_minutes       8825 non-null   float64\n",
      " 4   Genre                        10000 non-null  object \n",
      " 5   Host_Popularity_percentage   10000 non-null  float64\n",
      " 6   Publication_Day              10000 non-null  object \n",
      " 7   Publication_Time             10000 non-null  object \n",
      " 8   Guest_Popularity_percentage  8008 non-null   float64\n",
      " 9   Number_of_Ads                10000 non-null  float64\n",
      " 10  Episode_Sentiment            10000 non-null  object \n",
      " 11  Listening_Time_minutes       10000 non-null  float64\n",
      "dtypes: float64(5), int64(1), object(6)\n",
      "memory usage: 937.6+ KB\n",
      "None\n",
      "\n",
      "--- Basic Statistics (Numerical) ---\n",
      "                id  Episode_Length_minutes  Host_Popularity_percentage  \\\n",
      "count  10000.00000             8825.000000                10000.000000   \n",
      "mean    4999.50000               64.798698                   59.940578   \n",
      "std     2886.89568               33.103045                   22.933476   \n",
      "min        0.00000                5.000064                   20.000000   \n",
      "25%     2499.75000               35.830000                   39.390000   \n",
      "50%     4999.50000               64.180000                   60.080000   \n",
      "75%     7499.25000               94.450000                   79.660000   \n",
      "max     9999.00000              119.960000                   99.960000   \n",
      "\n",
      "       Guest_Popularity_percentage  Number_of_Ads  Listening_Time_minutes  \n",
      "count                  8008.000000   10000.000000            10000.000000  \n",
      "mean                     51.662475       1.348500               45.695784  \n",
      "std                      28.302334       1.101621               27.268595  \n",
      "min                       0.030000       0.000000                0.000000  \n",
      "25%                      27.770000       0.000000               23.518887  \n",
      "50%                      52.715000       1.000000               43.600770  \n",
      "75%                      75.620000       2.000000               64.996592  \n",
      "max                     107.080000       3.000000              119.970000  \n",
      "\n",
      "--- Basic Statistics (Categorical) ---\n",
      "       Podcast_Name Episode_Title   Genre Publication_Day Publication_Time  \\\n",
      "count         10000         10000   10000           10000            10000   \n",
      "unique           48           100      10               7                4   \n",
      "top      Tech Talks    Episode 69  Sports          Sunday          Evening   \n",
      "freq            290           148    1221            1513             2688   \n",
      "\n",
      "       Episode_Sentiment  \n",
      "count              10000  \n",
      "unique                 3  \n",
      "top              Neutral  \n",
      "freq                3426  \n",
      "\n",
      "--- Missing Values ---\n",
      "id                                0\n",
      "Podcast_Name                      0\n",
      "Episode_Title                     0\n",
      "Episode_Length_minutes         1175\n",
      "Genre                             0\n",
      "Host_Popularity_percentage        0\n",
      "Publication_Day                   0\n",
      "Publication_Time                  0\n",
      "Guest_Popularity_percentage    1992\n",
      "Number_of_Ads                     0\n",
      "Episode_Sentiment                 0\n",
      "Listening_Time_minutes            0\n",
      "dtype: int64\n",
      "Duplicated:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Initial Data ---\")\n",
    "print(df.head())\n",
    "print(\"\\n--- Data Info ---\")\n",
    "print(df.info())\n",
    "print(\"\\n--- Basic Statistics (Numerical) ---\")\n",
    "print(df.describe())\n",
    "print(\"\\n--- Basic Statistics (Categorical) ---\")\n",
    "print(df.describe(include='object'))\n",
    "print(\"\\n--- Missing Values ---\")\n",
    "print(df.isnull().sum())\n",
    "print(\"Duplicated:\")\n",
    "print(df.duplicated().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Identify feature types for ColumnTransformer\n",
    "numerical_features = ['Guest_Popularity_percentage', 'Host_Popularity_percentage', \"Number_of_Ads\", \"Episode_Length_minutes\"]\n",
    "nominal_features = ['Genre', 'Publication_Day', 'Publication_Time']\n",
    "ordinal_features = ['Episode_Sentiment']\n",
    "experience_order = ['Negative', 'Neutral', 'Positive']\n",
    "remove_features = [\"id\",\"Podcast_Name\",\"Episode_Title\"]\n",
    "target = \"Listening_Time_minutes\"\n",
    "\n",
    "# --- 2. Define Features and Target (for modeling) ---\n",
    "X = df.drop([target] + remove_features, axis=1)\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1b. Univariate Visualization (NEW SECTION) ---\n",
    "print(\"\\n--- Generating Univariate Visualizations ---\")\n",
    "\n",
    "\n",
    "# Plot numerical features\n",
    "print(\"Plotting numerical feature distributions...\")\n",
    "for col in numerical_features:\n",
    "    sns.histplot(df[col], kde=True)\n",
    "    plt.show()\n",
    "\n",
    "# Plot categorical features\n",
    "print(\"Plotting categorical feature distributions...\")\n",
    "for col in nominal_features + ordinal_features:\n",
    "    sns.countplot(data=df, x=col, order=df[col].value_counts().index) # Order bars by frequency\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data Split ---\n",
      "Training set shape: (8000, 8)\n",
      "Test set shape: (2000, 8)\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Train/Test Split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "print(f\"\\n--- Data Split ---\")\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num__Guest_Popularity_percentage</th>\n",
       "      <th>num__Host_Popularity_percentage</th>\n",
       "      <th>num__Number_of_Ads</th>\n",
       "      <th>num__Episode_Length_minutes</th>\n",
       "      <th>nom__Genre_Comedy</th>\n",
       "      <th>nom__Genre_Education</th>\n",
       "      <th>nom__Genre_Health</th>\n",
       "      <th>nom__Genre_Lifestyle</th>\n",
       "      <th>nom__Genre_Music</th>\n",
       "      <th>nom__Genre_News</th>\n",
       "      <th>...</th>\n",
       "      <th>nom__Publication_Day_Monday</th>\n",
       "      <th>nom__Publication_Day_Saturday</th>\n",
       "      <th>nom__Publication_Day_Sunday</th>\n",
       "      <th>nom__Publication_Day_Thursday</th>\n",
       "      <th>nom__Publication_Day_Tuesday</th>\n",
       "      <th>nom__Publication_Day_Wednesday</th>\n",
       "      <th>nom__Publication_Time_Evening</th>\n",
       "      <th>nom__Publication_Time_Morning</th>\n",
       "      <th>nom__Publication_Time_Night</th>\n",
       "      <th>ord__Episode_Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9254</th>\n",
       "      <td>-0.014637</td>\n",
       "      <td>-0.147502</td>\n",
       "      <td>1.495380</td>\n",
       "      <td>-1.362223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>0.420455</td>\n",
       "      <td>-1.246593</td>\n",
       "      <td>-1.227205</td>\n",
       "      <td>-0.925938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>0.527362</td>\n",
       "      <td>-0.837750</td>\n",
       "      <td>1.495380</td>\n",
       "      <td>-0.018595</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6087</th>\n",
       "      <td>-1.548269</td>\n",
       "      <td>1.032923</td>\n",
       "      <td>-0.319677</td>\n",
       "      <td>1.295088</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6669</th>\n",
       "      <td>-0.210370</td>\n",
       "      <td>1.349559</td>\n",
       "      <td>-1.227205</td>\n",
       "      <td>-0.834496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>-0.667079</td>\n",
       "      <td>-0.112707</td>\n",
       "      <td>-0.319677</td>\n",
       "      <td>1.101255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>0.030562</td>\n",
       "      <td>-0.182732</td>\n",
       "      <td>-0.319677</td>\n",
       "      <td>-0.018595</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>0.030562</td>\n",
       "      <td>1.068588</td>\n",
       "      <td>-1.227205</td>\n",
       "      <td>1.576499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>-1.210257</td>\n",
       "      <td>1.579206</td>\n",
       "      <td>1.495380</td>\n",
       "      <td>-0.798756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>0.030562</td>\n",
       "      <td>-1.081316</td>\n",
       "      <td>-1.227205</td>\n",
       "      <td>1.124438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      num__Guest_Popularity_percentage  num__Host_Popularity_percentage  \\\n",
       "9254                         -0.014637                        -0.147502   \n",
       "1561                          0.420455                        -1.246593   \n",
       "1670                          0.527362                        -0.837750   \n",
       "6087                         -1.548269                         1.032923   \n",
       "6669                         -0.210370                         1.349559   \n",
       "...                                ...                              ...   \n",
       "5734                         -0.667079                        -0.112707   \n",
       "5191                          0.030562                        -0.182732   \n",
       "5390                          0.030562                         1.068588   \n",
       "860                          -1.210257                         1.579206   \n",
       "7270                          0.030562                        -1.081316   \n",
       "\n",
       "      num__Number_of_Ads  num__Episode_Length_minutes  nom__Genre_Comedy  \\\n",
       "9254            1.495380                    -1.362223                0.0   \n",
       "1561           -1.227205                    -0.925938                0.0   \n",
       "1670            1.495380                    -0.018595                1.0   \n",
       "6087           -0.319677                     1.295088                1.0   \n",
       "6669           -1.227205                    -0.834496                0.0   \n",
       "...                  ...                          ...                ...   \n",
       "5734           -0.319677                     1.101255                0.0   \n",
       "5191           -0.319677                    -0.018595                1.0   \n",
       "5390           -1.227205                     1.576499                0.0   \n",
       "860             1.495380                    -0.798756                0.0   \n",
       "7270           -1.227205                     1.124438                0.0   \n",
       "\n",
       "      nom__Genre_Education  nom__Genre_Health  nom__Genre_Lifestyle  \\\n",
       "9254                   0.0                1.0                   0.0   \n",
       "1561                   0.0                0.0                   0.0   \n",
       "1670                   0.0                0.0                   0.0   \n",
       "6087                   0.0                0.0                   0.0   \n",
       "6669                   1.0                0.0                   0.0   \n",
       "...                    ...                ...                   ...   \n",
       "5734                   0.0                0.0                   0.0   \n",
       "5191                   0.0                0.0                   0.0   \n",
       "5390                   1.0                0.0                   0.0   \n",
       "860                    0.0                0.0                   0.0   \n",
       "7270                   0.0                1.0                   0.0   \n",
       "\n",
       "      nom__Genre_Music  nom__Genre_News  ...  nom__Publication_Day_Monday  \\\n",
       "9254               0.0              0.0  ...                          1.0   \n",
       "1561               0.0              0.0  ...                          0.0   \n",
       "1670               0.0              0.0  ...                          0.0   \n",
       "6087               0.0              0.0  ...                          0.0   \n",
       "6669               0.0              0.0  ...                          0.0   \n",
       "...                ...              ...  ...                          ...   \n",
       "5734               0.0              0.0  ...                          0.0   \n",
       "5191               0.0              0.0  ...                          0.0   \n",
       "5390               0.0              0.0  ...                          0.0   \n",
       "860                0.0              0.0  ...                          0.0   \n",
       "7270               0.0              0.0  ...                          0.0   \n",
       "\n",
       "      nom__Publication_Day_Saturday  nom__Publication_Day_Sunday  \\\n",
       "9254                            0.0                          0.0   \n",
       "1561                            0.0                          1.0   \n",
       "1670                            0.0                          0.0   \n",
       "6087                            0.0                          0.0   \n",
       "6669                            0.0                          1.0   \n",
       "...                             ...                          ...   \n",
       "5734                            0.0                          0.0   \n",
       "5191                            0.0                          0.0   \n",
       "5390                            1.0                          0.0   \n",
       "860                             1.0                          0.0   \n",
       "7270                            0.0                          1.0   \n",
       "\n",
       "      nom__Publication_Day_Thursday  nom__Publication_Day_Tuesday  \\\n",
       "9254                            0.0                           0.0   \n",
       "1561                            0.0                           0.0   \n",
       "1670                            0.0                           1.0   \n",
       "6087                            1.0                           0.0   \n",
       "6669                            0.0                           0.0   \n",
       "...                             ...                           ...   \n",
       "5734                            0.0                           1.0   \n",
       "5191                            0.0                           0.0   \n",
       "5390                            0.0                           0.0   \n",
       "860                             0.0                           0.0   \n",
       "7270                            0.0                           0.0   \n",
       "\n",
       "      nom__Publication_Day_Wednesday  nom__Publication_Time_Evening  \\\n",
       "9254                             0.0                            0.0   \n",
       "1561                             0.0                            1.0   \n",
       "1670                             0.0                            0.0   \n",
       "6087                             0.0                            0.0   \n",
       "6669                             0.0                            0.0   \n",
       "...                              ...                            ...   \n",
       "5734                             0.0                            0.0   \n",
       "5191                             1.0                            0.0   \n",
       "5390                             0.0                            1.0   \n",
       "860                              0.0                            0.0   \n",
       "7270                             0.0                            0.0   \n",
       "\n",
       "      nom__Publication_Time_Morning  nom__Publication_Time_Night  \\\n",
       "9254                            0.0                          1.0   \n",
       "1561                            0.0                          0.0   \n",
       "1670                            1.0                          0.0   \n",
       "6087                            0.0                          0.0   \n",
       "6669                            1.0                          0.0   \n",
       "...                             ...                          ...   \n",
       "5734                            0.0                          1.0   \n",
       "5191                            1.0                          0.0   \n",
       "5390                            0.0                          0.0   \n",
       "860                             0.0                          1.0   \n",
       "7270                            1.0                          0.0   \n",
       "\n",
       "      ord__Episode_Sentiment  \n",
       "9254                     2.0  \n",
       "1561                     0.0  \n",
       "1670                     2.0  \n",
       "6087                     2.0  \n",
       "6669                     1.0  \n",
       "...                      ...  \n",
       "5734                     0.0  \n",
       "5191                     1.0  \n",
       "5390                     0.0  \n",
       "860                      0.0  \n",
       "7270                     1.0  \n",
       "\n",
       "[8000 rows x 23 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 4. Preprocessing Pipelines ---\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "\n",
    "])\n",
    "\n",
    "nominal_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(sparse_output= False, drop = \"first\", handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "ordinal_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ordinal', OrdinalEncoder(categories=[experience_order]))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('nom', nominal_transformer, nominal_features),\n",
    "        ('ord', ordinal_transformer, ordinal_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ").set_output(transform=\"pandas\")\n",
    "\n",
    "X_train_tr = preprocessor.fit_transform(X_train)\n",
    "X_train_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['num__Guest_Popularity_percentage', 'num__Host_Popularity_percentage',\n",
       "       'num__Number_of_Ads', 'num__Episode_Length_minutes',\n",
       "       'nom__Genre_Comedy', 'nom__Genre_Education', 'nom__Genre_Health',\n",
       "       'nom__Genre_Lifestyle', 'nom__Genre_Music', 'nom__Genre_News',\n",
       "       'nom__Genre_Sports', 'nom__Genre_Technology', 'nom__Genre_True Crime',\n",
       "       'nom__Publication_Day_Monday', 'nom__Publication_Day_Saturday',\n",
       "       'nom__Publication_Day_Sunday', 'nom__Publication_Day_Thursday',\n",
       "       'nom__Publication_Day_Tuesday', 'nom__Publication_Day_Wednesday',\n",
       "       'nom__Publication_Time_Evening', 'nom__Publication_Time_Morning',\n",
       "       'nom__Publication_Time_Night', 'ord__Episode_Sentiment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== dummy ====================\n",
      "\n",
      "Starting CV\n",
      "CV Scores: [-27.32602897 -27.58588296 -27.08921934]\n",
      "Mean CV: -27.3337\n",
      "Std CV Accuracy: 0.2028\n",
      "\n",
      " Fit Model on Entire Training Set ---\n",
      "\n",
      "Evaluation\n",
      "732.1642938348867\n",
      "==================== lr ====================\n",
      "\n",
      "Starting CV\n",
      "CV Scores: [-14.59870962 -13.36672894 -13.87347052]\n",
      "Mean CV: -13.9463\n",
      "Std CV Accuracy: 0.5056\n",
      "\n",
      " Fit Model on Entire Training Set ---\n",
      "\n",
      "Evaluation\n",
      "194.1974516566448\n",
      "==================== hub ====================\n",
      "\n",
      "Starting CV\n",
      "CV Scores: [-14.59629896 -13.37134884 -13.87357118]\n",
      "Mean CV: -13.9471\n",
      "Std CV Accuracy: 0.5028\n",
      "\n",
      " Fit Model on Entire Training Set ---\n",
      "\n",
      "Evaluation\n",
      "194.19128398133472\n",
      "==================== rf ====================\n",
      "\n",
      "Starting CV\n",
      "CV Scores: [-16.02932427 -14.69789028 -15.2005344 ]\n",
      "Mean CV: -15.3092\n",
      "Std CV Accuracy: 0.5490\n",
      "\n",
      " Fit Model on Entire Training Set ---\n",
      "\n",
      "Evaluation\n",
      "244.23229236016797\n",
      "==================== SVR ====================\n",
      "\n",
      "Starting CV\n",
      "CV Scores: [-14.64162535 -13.50041162 -13.9180414 ]\n",
      "Mean CV: -14.0200\n",
      "Std CV Accuracy: 0.4714\n",
      "\n",
      " Fit Model on Entire Training Set ---\n",
      "\n",
      "Evaluation\n",
      "195.76628306456533\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, HuberRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# --- 5. Create Full Pipeline & Train with Cross-Validation (UPDATED SECTION) ---\n",
    "selector_estimator = DecisionTreeRegressor(random_state=42, max_depth=3)\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"dummy\" : DummyRegressor(),\n",
    "    \"lr\" : LinearRegression(),\n",
    "    \"hub\" : HuberRegressor(),\n",
    "    \"rf\" : RandomForestRegressor(random_state=42),\n",
    "    \"SVR\" : SVR(),\n",
    "}\n",
    "scoring = \"neg_root_mean_squared_error\"\n",
    "\n",
    "for name, model in models.items():\n",
    "    full_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('selector', SelectFromModel(estimator=selector_estimator)),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    print(\"=\"*20, name, \"=\"*20)\n",
    "    print(\"\\nStarting CV\")\n",
    "    cv_scores = cross_val_score(full_pipeline, X_train, y_train, cv=3, scoring=scoring)\n",
    "\n",
    "    print(f\"CV Scores: {cv_scores}\")\n",
    "    print(f\"Mean CV: {np.mean(cv_scores):.4f}\")\n",
    "    print(f\"Std CV Accuracy: {np.std(cv_scores):.4f}\")\n",
    "\n",
    "\n",
    "    print(f\"\\n Fit Model on Entire Training Set ---\")\n",
    "    full_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\nEvaluation\")\n",
    "    y_pred = full_pipeline.predict(X_test)\n",
    "    print(mean_squared_error(y_true=y_test, y_pred=y_pred))\n",
    "# y_pred_proba = full_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(f\"Accuracy on Test Set: {accuracy:.4f}\")\n",
    "\n",
    "# print(\"\\nClassification Report:\")\n",
    "# print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# print(\"\\nConfusion Matrix:\")\n",
    "# print(confusion_matrix(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Summary & Next Steps ---\n",
      "Successfully trained and evaluated a baseline Logistic Regression model.\n",
      "Cross-validation on the training set yielded a mean accuracy of ___.\n",
      "Achieved an accuracy of ____ on the unseen test data.\n",
      "Next steps if more time allowed:\n",
      "- More detailed EDA (bivariate analysis, correlations).\n",
      "- Experiment with different imputation strategies.\n",
      "- Feature engineering.\n",
      "- Try more complex models & hyperparameter tuning (guided by CV results).\n",
      "- Deeper error analysis.\n"
     ]
    }
   ],
   "source": [
    "# --- 7. Interpretation & Next Steps (Simulated) ---\n",
    "print(\"\\n--- Summary & Next Steps ---\")\n",
    "print(f\"Successfully trained and evaluated a baseline Logistic Regression model.\")\n",
    "print(f\"Cross-validation on the training set yielded a mean accuracy of ___.\")\n",
    "print(f\"Achieved an accuracy of ____ on the unseen test data.\")\n",
    "print(\"Next steps if more time allowed:\")\n",
    "print(\"- More detailed EDA (bivariate analysis, correlations).\")\n",
    "print(\"- Experiment with different imputation strategies.\")\n",
    "print(\"- Feature engineering.\")\n",
    "print(\"- Try more complex models & hyperparameter tuning (guided by CV results).\")\n",
    "print(\"- Deeper error analysis.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
